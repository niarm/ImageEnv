{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pickle\n",
    "import imageEnv\n",
    "import numpy as np\n",
    "import torch\n",
    "from imageEnv.perceptionFields import SimplePerceptionField\n",
    "import cv2\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import pycocotools\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('ImageEnv-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cap = dset.CocoDetection(root = 'data/coco/val2017',\n",
    "                        annFile = 'data/coco/annotations/instances_val2017.json',\n",
    "                        transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preparing image 4999'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = []\n",
    "masks = []\n",
    "\n",
    "for idx, el in enumerate(cap):\n",
    "    clear_output(wait=True)\n",
    "    display(\"preparing image {}\".format(idx))\n",
    "    image, target = el\n",
    "    categoryMask = np.zeros_like(image[0])\n",
    "    hasCategory = False\n",
    "    for instance in target:\n",
    "        if instance['category_id'] == 1:\n",
    "            hasCategory = True\n",
    "            mask = cap.coco.annToMask(instance)\n",
    "            categoryMask += mask\n",
    "            \n",
    "    if hasCategory == True:\n",
    "        categoryMask = np.clip(categoryMask,0.0,1.0)\n",
    "        images.append(image.permute(1, 2, 0).numpy())\n",
    "        masks.append(categoryMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image in enumerate(images):\n",
    "    targetImage = (image * 255).astype(np.uint8)\n",
    "    out = Image.fromarray(targetImage)\n",
    "    out.save(\"data/input/images/\"+str(i)+\".jpg\")\n",
    "    \n",
    "for i, mask in enumerate(masks):\n",
    "    targetMask = (mask * 255).astype(np.uint8)\n",
    "    out = Image.fromarray(targetMask)\n",
    "    out.save(\"data/input/masks/\"+str(i)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"data/input/masks/2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
